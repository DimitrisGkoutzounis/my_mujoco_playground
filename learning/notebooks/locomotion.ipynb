{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpkYHwCqk7W-"
      },
      "source": [
        "![MuJoCo banner](https://raw.githubusercontent.com/google-deepmind/mujoco/main/banner.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBSdkbmGN2K-"
      },
      "source": [
        "### Copyright notice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UbO9uhtBSX5"
      },
      "source": [
        "> <p><small><small>Copyright 2025 DeepMind Technologies Limited.</small></p>\n",
        "> <p><small><small>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at <a href=\"http://www.apache.org/licenses/LICENSE-2.0\">http://www.apache.org/licenses/LICENSE-2.0</a>.</small></small></p>\n",
        "> <p><small><small>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</small></small></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNIJkb_FM2Ux"
      },
      "source": [
        "# Locomotion in The Playground! <a href=\"https://colab.research.google.com/github/google-deepmind/mujoco_playground/blob/main/learning/notebooks/locomotion.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" width=\"140\" align=\"center\"/></a>\n",
        "\n",
        "In this notebook, we'll walk through a few locomotion environments available in MuJoCo Playground.\n",
        "\n",
        "**A Colab runtime with GPU acceleration is required.** If you're using a CPU-only runtime, you can switch using the menu \"Runtime > Change runtime type\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Xqo7pyX-n72M"
      },
      "outputs": [],
      "source": [
        "#@title Install pre-requisites\n",
        "!pip install mujoco\n",
        "!pip install mujoco_mjx\n",
        "!pip install brax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "IbZxYDxzoz5R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Apr 16 16:58:36 2025       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA GeForce RTX 3060        Off | 00000000:01:00.0  On |                  N/A |\n",
            "|  0%   49C    P5              22W / 170W |  11949MiB / 12288MiB |     14%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|    0   N/A  N/A      1114      G   /usr/lib/xorg/Xorg                           59MiB |\n",
            "|    0   N/A  N/A      1521      G   /usr/lib/xorg/Xorg                          330MiB |\n",
            "|    0   N/A  N/A      1651      G   /usr/bin/gnome-shell                         35MiB |\n",
            "|    0   N/A  N/A      1899    C+G   /usr/bin/anydesk                              6MiB |\n",
            "|    0   N/A  N/A      2110      G   /usr/lib/firefox/firefox                    253MiB |\n",
            "|    0   N/A  N/A     11134      G   ...erProcess --variations-seed-version      161MiB |\n",
            "|    0   N/A  N/A     73492      C   ...s/mjx_playground_madrona/bin/python    10938MiB |\n",
            "|    0   N/A  N/A     76889      C   python                                      108MiB |\n",
            "+---------------------------------------------------------------------------------------+\n",
            "Setting environment variable to use GPU rendering:\n",
            "env: MUJOCO_GL=egl\n",
            "Checking that the installation succeeded:\n",
            "Installation successful.\n"
          ]
        }
      ],
      "source": [
        "# @title Check if MuJoCo installation was successful\n",
        "\n",
        "import distutils.util\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "if subprocess.run('nvidia-smi').returncode:\n",
        "  raise RuntimeError(\n",
        "      'Cannot communicate with GPU. '\n",
        "      'Make sure you are using a GPU Colab runtime. '\n",
        "      'Go to the Runtime menu and select Choose runtime type.'\n",
        "  )\n",
        "\n",
        "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
        "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
        "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
        "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
        "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
        "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
        "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
        "    f.write(\"\"\"{\n",
        "    \"file_format_version\" : \"1.0.0\",\n",
        "    \"ICD\" : {\n",
        "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
        "print('Setting environment variable to use GPU rendering:')\n",
        "%env MUJOCO_GL=egl\n",
        "\n",
        "try:\n",
        "  print('Checking that the installation succeeded:')\n",
        "  import mujoco\n",
        "\n",
        "  mujoco.MjModel.from_xml_string('<mujoco/>')\n",
        "except Exception as e:\n",
        "  raise e from RuntimeError(\n",
        "      'Something went wrong during installation. Check the shell output above '\n",
        "      'for more information.\\n'\n",
        "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
        "      'by going to the Runtime menu and selecting \"Choose runtime type\".'\n",
        "  )\n",
        "\n",
        "print('Installation successful.')\n",
        "\n",
        "# Tell XLA to use Triton GEMM, this improves steps/sec by ~30% on some GPUs\n",
        "xla_flags = os.environ.get('XLA_FLAGS', '')\n",
        "xla_flags += ' --xla_gpu_triton_gemm_any=True'\n",
        "os.environ['XLA_FLAGS'] = xla_flags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "T5f4w3Kq2X14"
      },
      "outputs": [],
      "source": [
        "# @title Import packages for plotting and creating graphics\n",
        "import json\n",
        "import itertools\n",
        "import time\n",
        "from typing import Callable, List, NamedTuple, Optional, Union\n",
        "import numpy as np\n",
        "\n",
        "# Graphics and plotting.\n",
        "# print(\"Installing mediapy:\")\n",
        "# !command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
        "# !pip install -q mediapy\n",
        "import mediapy as media\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# More legible printing from numpy.\n",
        "np.set_printoptions(precision=3, suppress=True, linewidth=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "ObF1UXrkb0Nd"
      },
      "outputs": [],
      "source": [
        "# @title Import MuJoCo, MJX, and Brax\n",
        "from datetime import datetime\n",
        "import functools\n",
        "import os\n",
        "from typing import Any, Dict, Sequence, Tuple, Union\n",
        "from brax import base\n",
        "from brax import envs\n",
        "from brax import math\n",
        "from brax.base import Base, Motion, Transform\n",
        "from brax.base import State as PipelineState\n",
        "from brax.envs.base import Env, PipelineEnv, State\n",
        "from brax.io import html, mjcf, model\n",
        "from brax.mjx.base import State as MjxState\n",
        "from brax.training.agents.ppo import networks as ppo_networks\n",
        "from brax.training.agents.ppo import train as ppo\n",
        "from brax.training.agents.sac import networks as sac_networks\n",
        "from brax.training.agents.sac import train as sac\n",
        "from etils import epath\n",
        "from flax import struct\n",
        "from flax.training import orbax_utils\n",
        "from IPython.display import HTML, clear_output\n",
        "import jax\n",
        "from jax import numpy as jp\n",
        "from matplotlib import pyplot as plt\n",
        "import mediapy as media\n",
        "from ml_collections import config_dict\n",
        "import mujoco\n",
        "from mujoco import mjx\n",
        "import numpy as np\n",
        "from orbax import checkpoint as ocp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UoTLSx4cFRdy"
      },
      "outputs": [],
      "source": [
        "#@title Install MuJoCo Playground\n",
        "# !pip install playground"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "gYm2h7m8w3Nv"
      },
      "outputs": [],
      "source": [
        "#@title Import The Playground\n",
        "\n",
        "from mujoco_playground import wrapper\n",
        "from mujoco_playground import registry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcibXbyKt4FI"
      },
      "source": [
        "# Locomotion\n",
        "\n",
        "MuJoCo Playground contains a host of quadrupedal and bipedal environments (all listed below after running the command)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ox0Gze9Ct5AM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('BarkourJoystick',\n",
              " 'BerkeleyHumanoidJoystickFlatTerrain',\n",
              " 'BerkeleyHumanoidJoystickRoughTerrain',\n",
              " 'G1JoystickFlatTerrain',\n",
              " 'G1JoystickRoughTerrain',\n",
              " 'Go1JoystickFlatTerrain',\n",
              " 'Go1JoystickRoughTerrain',\n",
              " 'Go1Getup',\n",
              " 'Go1Handstand',\n",
              " 'Go1Footstand',\n",
              " 'Go2JoystickFlatTerrain',\n",
              " 'Go2JoystickRoughTerrain',\n",
              " 'Go2Getup',\n",
              " 'Go2Handstand',\n",
              " 'Go2Footstand',\n",
              " 'H1InplaceGaitTracking',\n",
              " 'H1JoystickGaitTracking',\n",
              " 'Op3Joystick',\n",
              " 'SpotFlatTerrainJoystick',\n",
              " 'SpotGetup',\n",
              " 'SpotJoystickGaitTracking',\n",
              " 'T1JoystickFlatTerrain',\n",
              " 'T1JoystickRoughTerrain')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "registry.locomotion.ALL_ENVS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R01tjWfI-i6"
      },
      "source": [
        "# Quadrupedal\n",
        "\n",
        "Let's jump right into quadrupedal locomotion! While we have environments available for the Google Barkour and Boston Dynamics Spot robots, the Unitree Go1 environment contains the most trainable policies that were transferred onto the real robot. We'll go right ahead and show a few policies using the Unitree Go1!\n",
        "\n",
        "First, let's train a joystick policy, which tracks linear and yaw velocity commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kPJeoQeEJBSA"
      },
      "outputs": [],
      "source": [
        "env_name = 'Go1JoystickFlatTerrain'\n",
        "env = registry.load(env_name)\n",
        "env_cfg = registry.get_default_config(env_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6n9UT9N1wR5K"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Kd: 0.5\n",
              "Kp: 35.0\n",
              "action_repeat: 1\n",
              "action_scale: 0.5\n",
              "command_config:\n",
              "  a:\n",
              "  - 1.5\n",
              "  - 0.8\n",
              "  - 1.2\n",
              "  b:\n",
              "  - 0.9\n",
              "  - 0.25\n",
              "  - 0.5\n",
              "ctrl_dt: 0.02\n",
              "episode_length: 1000\n",
              "history_len: 1\n",
              "noise_config:\n",
              "  level: 1.0\n",
              "  scales:\n",
              "    gravity: 0.05\n",
              "    gyro: 0.2\n",
              "    joint_pos: 0.03\n",
              "    joint_vel: 1.5\n",
              "    linvel: 0.1\n",
              "pert_config:\n",
              "  enable: false\n",
              "  kick_durations:\n",
              "  - 0.05\n",
              "  - 0.2\n",
              "  kick_wait_times:\n",
              "  - 1.0\n",
              "  - 3.0\n",
              "  velocity_kick:\n",
              "  - 0.0\n",
              "  - 3.0\n",
              "reward_config:\n",
              "  max_foot_height: 0.1\n",
              "  scales:\n",
              "    action_rate: -0.01\n",
              "    ang_vel_xy: -0.05\n",
              "    dof_pos_limits: -1.0\n",
              "    energy: -0.001\n",
              "    feet_air_time: 0.1\n",
              "    feet_clearance: -2.0\n",
              "    feet_height: -0.2\n",
              "    feet_slip: -0.1\n",
              "    lin_vel_z: -0.5\n",
              "    orientation: -5.0\n",
              "    pose: 0.5\n",
              "    stand_still: -1.0\n",
              "    termination: -1.0\n",
              "    torques: -0.0002\n",
              "    tracking_ang_vel: 0.5\n",
              "    tracking_lin_vel: 1.0\n",
              "  tracking_sigma: 0.25\n",
              "sim_dt: 0.004\n",
              "soft_joint_pos_limit_factor: 0.95"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env_cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thm7nZueM4cz"
      },
      "source": [
        "## Joystick\n",
        "\n",
        "Let's train the joystick policy and visualize rollouts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "B9T_UVZYLDdM"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "action_repeat: 1\n",
              "batch_size: 256\n",
              "discounting: 0.97\n",
              "entropy_cost: 0.01\n",
              "episode_length: 1000\n",
              "learning_rate: 0.0003\n",
              "max_grad_norm: 1.0\n",
              "network_factory:\n",
              "  policy_hidden_layer_sizes: &id001 !!python/tuple\n",
              "  - 512\n",
              "  - 256\n",
              "  - 128\n",
              "  policy_obs_key: state\n",
              "  value_hidden_layer_sizes: *id001\n",
              "  value_obs_key: privileged_state\n",
              "normalize_observations: true\n",
              "num_envs: 8192\n",
              "num_evals: 10\n",
              "num_minibatches: 32\n",
              "num_resets_per_eval: 1\n",
              "num_timesteps: 200000000\n",
              "num_updates_per_batch: 4\n",
              "reward_scaling: 1.0\n",
              "unroll_length: 20"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mujoco_playground.config import locomotion_params\n",
        "ppo_params = locomotion_params.brax_ppo_config(env_name)\n",
        "ppo_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aefr2OS01D9g"
      },
      "source": [
        "Domain randomization was used to make the policy robust to sim-to-real transfer. Certain environments in the Playground have domain randomization functions implemented. They're available in the registry and can be passed directly to brax RL algorithms. The [domain randomization](https://github.com/google-deepmind/mujoco_playground/blob/main/mujoco_playground/_src/locomotion/go1/randomize.py) function randomizes over friction, armature, center of mass of the torso, and link masses, amongst other simulation parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UVA4Bn681DZT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function mujoco_playground._src.locomotion.go1.randomize.domain_randomize(model: mujoco.mjx._src.types.Model, rng: jax.Array)>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "registry.get_domain_randomizer(env_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBEEQyY6M5OC"
      },
      "source": [
        "### Train\n",
        "\n",
        "The policy takes 7 minutes to train on an RTX 4090."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "XKFzyP7wM5OD"
      },
      "outputs": [],
      "source": [
        "x_data, y_data, y_dataerr = [], [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  times.append(datetime.now())\n",
        "  x_data.append(num_steps)\n",
        "  y_data.append(metrics[\"eval/episode_reward\"])\n",
        "  y_dataerr.append(metrics[\"eval/episode_reward_std\"])\n",
        "\n",
        "  plt.xlim([0, ppo_params[\"num_timesteps\"] * 1.25])\n",
        "  plt.xlabel(\"# environment steps\")\n",
        "  plt.ylabel(\"reward per episode\")\n",
        "  plt.title(f\"y={y_data[-1]:.3f}\")\n",
        "  plt.errorbar(x_data, y_data, yerr=y_dataerr, color=\"blue\")\n",
        "\n",
        "  display(plt.gcf())\n",
        "\n",
        "randomizer = registry.get_domain_randomizer(env_name)\n",
        "ppo_training_params = dict(ppo_params)\n",
        "network_factory = ppo_networks.make_ppo_networks\n",
        "if \"network_factory\" in ppo_params:\n",
        "  del ppo_training_params[\"network_factory\"]\n",
        "  network_factory = functools.partial(\n",
        "      ppo_networks.make_ppo_networks,\n",
        "      **ppo_params.network_factory\n",
        "  )\n",
        "\n",
        "train_fn = functools.partial(\n",
        "    ppo.train, **dict(ppo_training_params),\n",
        "    network_factory=network_factory,\n",
        "    randomization_fn=randomizer,\n",
        "    progress_fn=progress\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGrlulWbM5OD"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "make_inference_fn, params, metrics = train_fn(\n",
        "    environment=env,\n",
        "    eval_env=registry.load(env_name, config=env_cfg),\n",
        "    wrap_env_fn=wrapper.wrap_for_brax_training,\n",
        ")\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "print(f\"time to train: {times[-1] - times[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUxSNhq3UqmC"
      },
      "source": [
        "Let's rollout and render the resulting policy!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBM89g5A2Yoi"
      },
      "outputs": [],
      "source": [
        "# Enable perturbation in the eval env.\n",
        "env_cfg = registry.get_default_config(env_name)\n",
        "env_cfg.pert_config.enable = True\n",
        "env_cfg.pert_config.velocity_kick = [3.0, 6.0]\n",
        "env_cfg.pert_config.kick_wait_times = [5.0, 15.0]\n",
        "env_cfg.command_config.a = [1.5, 0.8, 2*jp.pi]\n",
        "eval_env = registry.load(env_name, config=env_cfg)\n",
        "velocity_kick_range = [0.0, 0.0]  # Disable velocity kick.\n",
        "kick_duration_range = [0.05, 0.2]\n",
        "\n",
        "jit_reset = jax.jit(eval_env.reset)\n",
        "jit_step = jax.jit(eval_env.step)\n",
        "jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "C_1CY9xDoUKw"
      },
      "outputs": [],
      "source": [
        "#@title Rollout and Render\n",
        "from mujoco_playground._src.gait import draw_joystick_command\n",
        "\n",
        "x_vel = 0.0  #@param {type: \"number\"}\n",
        "y_vel = 0.0  #@param {type: \"number\"}\n",
        "yaw_vel = 3.14  #@param {type: \"number\"}\n",
        "\n",
        "\n",
        "def sample_pert(rng):\n",
        "  rng, key1, key2 = jax.random.split(rng, 3)\n",
        "  pert_mag = jax.random.uniform(\n",
        "      key1, minval=velocity_kick_range[0], maxval=velocity_kick_range[1]\n",
        "  )\n",
        "  duration_seconds = jax.random.uniform(\n",
        "      key2, minval=kick_duration_range[0], maxval=kick_duration_range[1]\n",
        "  )\n",
        "  duration_steps = jp.round(duration_seconds / eval_env.dt).astype(jp.int32)\n",
        "  state.info[\"pert_mag\"] = pert_mag\n",
        "  state.info[\"pert_duration\"] = duration_steps\n",
        "  state.info[\"pert_duration_seconds\"] = duration_seconds\n",
        "  return rng\n",
        "\n",
        "\n",
        "rng = jax.random.PRNGKey(0)\n",
        "rollout = []\n",
        "modify_scene_fns = []\n",
        "\n",
        "swing_peak = []\n",
        "rewards = []\n",
        "linvel = []\n",
        "angvel = []\n",
        "track = []\n",
        "foot_vel = []\n",
        "rews = []\n",
        "contact = []\n",
        "command = jp.array([x_vel, y_vel, yaw_vel])\n",
        "\n",
        "state = jit_reset(rng)\n",
        "if state.info[\"steps_since_last_pert\"] < state.info[\"steps_until_next_pert\"]:\n",
        "  rng = sample_pert(rng)\n",
        "state.info[\"command\"] = command\n",
        "for i in range(env_cfg.episode_length):\n",
        "  if state.info[\"steps_since_last_pert\"] < state.info[\"steps_until_next_pert\"]:\n",
        "    rng = sample_pert(rng)\n",
        "  act_rng, rng = jax.random.split(rng)\n",
        "  ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "  state = jit_step(state, ctrl)\n",
        "  state.info[\"command\"] = command\n",
        "  rews.append(\n",
        "      {k: v for k, v in state.metrics.items() if k.startswith(\"reward/\")}\n",
        "  )\n",
        "  rollout.append(state)\n",
        "  swing_peak.append(state.info[\"swing_peak\"])\n",
        "  rewards.append(\n",
        "      {k[7:]: v for k, v in state.metrics.items() if k.startswith(\"reward/\")}\n",
        "  )\n",
        "  linvel.append(env.get_global_linvel(state.data))\n",
        "  angvel.append(env.get_gyro(state.data))\n",
        "  track.append(\n",
        "      env._reward_tracking_lin_vel(\n",
        "          state.info[\"command\"], env.get_local_linvel(state.data)\n",
        "      )\n",
        "  )\n",
        "\n",
        "  feet_vel = state.data.sensordata[env._foot_linvel_sensor_adr]\n",
        "  vel_xy = feet_vel[..., :2]\n",
        "  vel_norm = jp.sqrt(jp.linalg.norm(vel_xy, axis=-1))\n",
        "  foot_vel.append(vel_norm)\n",
        "\n",
        "  contact.append(state.info[\"last_contact\"])\n",
        "\n",
        "  xyz = np.array(state.data.xpos[env._torso_body_id])\n",
        "  xyz += np.array([0, 0, 0.2])\n",
        "  x_axis = state.data.xmat[env._torso_body_id, 0]\n",
        "  yaw = -np.arctan2(x_axis[1], x_axis[0])\n",
        "  modify_scene_fns.append(\n",
        "      functools.partial(\n",
        "          draw_joystick_command,\n",
        "          cmd=state.info[\"command\"],\n",
        "          xyz=xyz,\n",
        "          theta=yaw,\n",
        "          scl=abs(state.info[\"command\"][0])\n",
        "          / env_cfg.command_config.a[0],\n",
        "      )\n",
        "  )\n",
        "\n",
        "\n",
        "render_every = 2\n",
        "fps = 1.0 / eval_env.dt / render_every\n",
        "traj = rollout[::render_every]\n",
        "mod_fns = modify_scene_fns[::render_every]\n",
        "\n",
        "scene_option = mujoco.MjvOption()\n",
        "scene_option.geomgroup[2] = True\n",
        "scene_option.geomgroup[3] = False\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = True\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = False\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_PERTFORCE] = True\n",
        "\n",
        "frames = eval_env.render(\n",
        "    traj,\n",
        "    camera=\"track\",\n",
        "    scene_option=scene_option,\n",
        "    width=640,\n",
        "    height=480,\n",
        "    modify_scene_fns=mod_fns,\n",
        ")\n",
        "media.show_video(frames, fps=fps, loop=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QHdoJ2r30En"
      },
      "source": [
        "Let's visualize the feet positions and the positional drift compared to the commanded linear and angular velocity. This is useful for debugging how well the policy follows the commands!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "gyyynm3ozEet"
      },
      "outputs": [],
      "source": [
        "#@title Plot each foot in a 2x2 grid.\n",
        "\n",
        "swing_peak = jp.array(swing_peak)\n",
        "names = [\"FR\", \"FL\", \"RR\", \"RL\"]\n",
        "colors = [\"r\", \"g\", \"b\", \"y\"]\n",
        "fig, axs = plt.subplots(2, 2)\n",
        "for i, ax in enumerate(axs.flat):\n",
        "  ax.plot(swing_peak[:, i], color=colors[i])\n",
        "  ax.set_ylim([0, env_cfg.reward_config.max_foot_height * 1.25])\n",
        "  ax.axhline(env_cfg.reward_config.max_foot_height, color=\"k\", linestyle=\"--\")\n",
        "  ax.set_title(names[i])\n",
        "  ax.set_xlabel(\"time\")\n",
        "  ax.set_ylabel(\"height\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "linvel_x = jp.array(linvel)[:, 0]\n",
        "linvel_y = jp.array(linvel)[:, 1]\n",
        "angvel_yaw = jp.array(angvel)[:, 2]\n",
        "\n",
        "# Plot whether velocity is within the command range.\n",
        "linvel_x = jp.convolve(linvel_x, jp.ones(10) / 10, mode=\"same\")\n",
        "linvel_y = jp.convolve(linvel_y, jp.ones(10) / 10, mode=\"same\")\n",
        "angvel_yaw = jp.convolve(angvel_yaw, jp.ones(10) / 10, mode=\"same\")\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(10, 10))\n",
        "axes[0].plot(linvel_x)\n",
        "axes[1].plot(linvel_y)\n",
        "axes[2].plot(angvel_yaw)\n",
        "\n",
        "axes[0].set_ylim(\n",
        "    -env_cfg.command_config.a[0], env_cfg.command_config.a[0]\n",
        ")\n",
        "axes[1].set_ylim(\n",
        "    -env_cfg.command_config.a[1], env_cfg.command_config.a[1]\n",
        ")\n",
        "axes[2].set_ylim(\n",
        "    -env_cfg.command_config.a[2], env_cfg.command_config.a[2]\n",
        ")\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "  ax.axhline(state.info[\"command\"][i], color=\"red\", linestyle=\"--\")\n",
        "\n",
        "labels = [\"dx\", \"dy\", \"dyaw\"]\n",
        "for i, ax in enumerate(axes):\n",
        "  ax.set_ylabel(labels[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1QAHuYBQBbl"
      },
      "source": [
        "Now let's visualize what it looks like to slowly increase linear velocity commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Q0EuQiVlzh5u"
      },
      "outputs": [],
      "source": [
        "#@title Slowly increase linvel commands\n",
        "\n",
        "rng = jax.random.PRNGKey(0)\n",
        "rollout = []\n",
        "modify_scene_fns = []\n",
        "swing_peak = []\n",
        "linvel = []\n",
        "angvel = []\n",
        "\n",
        "x = -0.25\n",
        "command = jp.array([x, 0, 0])\n",
        "state = jit_reset(rng)\n",
        "for i in range(1_400):\n",
        "  # Increase the forward velocity by 0.25 m/s every 200 steps.\n",
        "  if i % 200 == 0:\n",
        "    x += 0.25\n",
        "    print(f\"Setting x to {x}\")\n",
        "    command = jp.array([x, 0, 0])\n",
        "  state.info[\"command\"] = command\n",
        "  if state.info[\"steps_since_last_pert\"] < state.info[\"steps_until_next_pert\"]:\n",
        "    rng = sample_pert(rng)\n",
        "  act_rng, rng = jax.random.split(rng)\n",
        "  ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "  state = jit_step(state, ctrl)\n",
        "  rollout.append(state)\n",
        "  swing_peak.append(state.info[\"swing_peak\"])\n",
        "  linvel.append(env.get_global_linvel(state.data))\n",
        "  angvel.append(env.get_gyro(state.data))\n",
        "  xyz = np.array(state.data.xpos[env._torso_body_id])\n",
        "  xyz += np.array([0, 0, 0.2])\n",
        "  x_axis = state.data.xmat[env._torso_body_id, 0]\n",
        "  yaw = -np.arctan2(x_axis[1], x_axis[0])\n",
        "  modify_scene_fns.append(\n",
        "      functools.partial(\n",
        "          draw_joystick_command,\n",
        "          cmd=command,\n",
        "          xyz=xyz,\n",
        "          theta=yaw,\n",
        "          scl=abs(command[0]) / env_cfg.command_config.a[0],\n",
        "      )\n",
        "  )\n",
        "\n",
        "\n",
        "# Plot each foot in a 2x2 grid.\n",
        "swing_peak = jp.array(swing_peak)\n",
        "names = [\"FR\", \"FL\", \"RR\", \"RL\"]\n",
        "colors = [\"r\", \"g\", \"b\", \"y\"]\n",
        "fig, axs = plt.subplots(2, 2)\n",
        "for i, ax in enumerate(axs.flat):\n",
        "  ax.plot(swing_peak[:, i], color=colors[i])\n",
        "  ax.set_ylim([0, env_cfg.reward_config.max_foot_height * 1.25])\n",
        "  ax.axhline(env_cfg.reward_config.max_foot_height, color=\"k\", linestyle=\"--\")\n",
        "  ax.set_title(names[i])\n",
        "  ax.set_xlabel(\"time\")\n",
        "  ax.set_ylabel(\"height\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "linvel_x = jp.array(linvel)[:, 0]\n",
        "linvel_y = jp.array(linvel)[:, 1]\n",
        "angvel_yaw = jp.array(angvel)[:, 2]\n",
        "\n",
        "# Plot whether velocity is within the command range.\n",
        "linvel_x = jp.convolve(linvel_x, jp.ones(10) / 10, mode=\"same\")\n",
        "linvel_y = jp.convolve(linvel_y, jp.ones(10) / 10, mode=\"same\")\n",
        "angvel_yaw = jp.convolve(angvel_yaw, jp.ones(10) / 10, mode=\"same\")\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(10, 10))\n",
        "axes[0].plot(linvel_x)\n",
        "axes[1].plot(linvel_y)\n",
        "axes[2].plot(angvel_yaw)\n",
        "\n",
        "axes[0].set_ylim(\n",
        "    -env_cfg.command_config.a[0], env_cfg.command_config.a[0]\n",
        ")\n",
        "axes[1].set_ylim(\n",
        "    -env_cfg.command_config.a[1], env_cfg.command_config.a[1]\n",
        ")\n",
        "axes[2].set_ylim(\n",
        "    -env_cfg.command_config.a[2], env_cfg.command_config.a[2]\n",
        ")\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "  ax.axhline(state.info[\"command\"][i], color=\"red\", linestyle=\"--\")\n",
        "\n",
        "labels = [\"dx\", \"dy\", \"dyaw\"]\n",
        "for i, ax in enumerate(axes):\n",
        "  ax.set_ylabel(labels[i])\n",
        "\n",
        "\n",
        "render_every = 2\n",
        "fps = 1.0 / eval_env.dt / render_every\n",
        "print(f\"fps: {fps}\")\n",
        "\n",
        "traj = rollout[::render_every]\n",
        "mod_fns = modify_scene_fns[::render_every]\n",
        "assert len(traj) == len(mod_fns)\n",
        "\n",
        "scene_option = mujoco.MjvOption()\n",
        "scene_option.geomgroup[2] = True\n",
        "scene_option.geomgroup[3] = False\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = True\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_PERTFORCE] = True\n",
        "\n",
        "frames = eval_env.render(\n",
        "    traj,\n",
        "    camera=\"track\",\n",
        "    height=480,\n",
        "    width=640,\n",
        "    modify_scene_fns=mod_fns,\n",
        "    scene_option=scene_option,\n",
        ")\n",
        "media.show_video(frames, fps=fps, loop=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RHZvXgmzrEJ"
      },
      "source": [
        "## Handstand\n",
        "\n",
        "Additional policies are available for the Unitree Go1 such as fall-recovery, handstand, and footstand policies. We'll use the handstand policy as an opportunity to demonstrate finetuning policies from prior checkpoints. This will allow us to quickly iterate on training curriculums by modifying the enviornment config between runs.\n",
        "\n",
        "For the Go1 handstand policy, we'll first train with the default configuration, and then add an energy penalty to make the policy smoother and more likely to transfer onto the robot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYriZOAxzEk_"
      },
      "outputs": [],
      "source": [
        "from mujoco_playground.config import locomotion_params\n",
        "\n",
        "env_name = 'Go1Handstand'\n",
        "env = registry.load(env_name)\n",
        "env_cfg = registry.get_default_config(env_name)\n",
        "ppo_params = locomotion_params.brax_ppo_config(env_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nB5ugbdS5kk"
      },
      "source": [
        "Let's create a checkpoint directory and then train a policy with checkpointing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyEDpHisS7eO"
      },
      "outputs": [],
      "source": [
        "ckpt_path = epath.Path(\"checkpoints\").resolve() / env_name\n",
        "ckpt_path.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"{ckpt_path}\")\n",
        "\n",
        "with open(ckpt_path / \"config.json\", \"w\") as fp:\n",
        "  json.dump(env_cfg.to_dict(), fp, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCRUYofXSNGT"
      },
      "outputs": [],
      "source": [
        "#@title Training fn definition\n",
        "x_data, y_data, y_dataerr = [], [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "\n",
        "def policy_params_fn(current_step, make_policy, params):\n",
        "  del make_policy  # Unused.\n",
        "  orbax_checkpointer = ocp.PyTreeCheckpointer()\n",
        "  save_args = orbax_utils.save_args_from_target(params)\n",
        "  path = ckpt_path / f\"{current_step}\"\n",
        "  orbax_checkpointer.save(path, params, force=True, save_args=save_args)\n",
        "\n",
        "\n",
        "def progress(num_steps, metrics):\n",
        "  clear_output(wait=True)\n",
        "\n",
        "  times.append(datetime.now())\n",
        "  x_data.append(num_steps)\n",
        "  y_data.append(metrics[\"eval/episode_reward\"])\n",
        "  y_dataerr.append(metrics[\"eval/episode_reward_std\"])\n",
        "\n",
        "  plt.xlim([0, ppo_params[\"num_timesteps\"] * 1.25])\n",
        "  plt.xlabel(\"# environment steps\")\n",
        "  plt.ylabel(\"reward per episode\")\n",
        "  plt.title(f\"y={y_data[-1]:.3f}\")\n",
        "  plt.errorbar(x_data, y_data, yerr=y_dataerr, color=\"blue\")\n",
        "\n",
        "  display(plt.gcf())\n",
        "\n",
        "randomizer = registry.get_domain_randomizer(env_name)\n",
        "ppo_training_params = dict(ppo_params)\n",
        "network_factory = ppo_networks.make_ppo_networks\n",
        "if \"network_factory\" in ppo_params:\n",
        "  del ppo_training_params[\"network_factory\"]\n",
        "  network_factory = functools.partial(\n",
        "      ppo_networks.make_ppo_networks,\n",
        "      **ppo_params.network_factory\n",
        "  )\n",
        "\n",
        "train_fn = functools.partial(\n",
        "    ppo.train, **dict(ppo_training_params),\n",
        "    network_factory=network_factory,\n",
        "    randomization_fn=randomizer,\n",
        "    progress_fn=progress,\n",
        "    policy_params_fn=policy_params_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1oK80x1anPp"
      },
      "source": [
        "The initial policy takes 8 minutes to train on an RTX 4090."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY6P3abhSNGU"
      },
      "outputs": [],
      "source": [
        "make_inference_fn, params, metrics = train_fn(\n",
        "    environment=registry.load(env_name, config=env_cfg),\n",
        "    eval_env=registry.load(env_name, config=env_cfg),\n",
        "    wrap_env_fn=wrapper.wrap_for_brax_training,\n",
        ")\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "print(f\"time to train: {times[-1] - times[1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s6PkZ4GWV4Z"
      },
      "source": [
        "Let's visualize the current policy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WiWOtc_6WbcX"
      },
      "outputs": [],
      "source": [
        "#@title Rollout and Render\n",
        "inference_fn = make_inference_fn(params, deterministic=True)\n",
        "jit_inference_fn = jax.jit(inference_fn)\n",
        "\n",
        "eval_env = registry.load(env_name, config=env_cfg)\n",
        "jit_reset = jax.jit(eval_env.reset)\n",
        "jit_step = jax.jit(eval_env.step)\n",
        "\n",
        "rng = jax.random.PRNGKey(12345)\n",
        "rollout = []\n",
        "rewards = []\n",
        "torso_height = []\n",
        "actions = []\n",
        "torques = []\n",
        "power = []\n",
        "qfrc_constraint = []\n",
        "qvels = []\n",
        "power1 = []\n",
        "power2 = []\n",
        "for _ in range(10):\n",
        "  rng, reset_rng = jax.random.split(rng)\n",
        "  state = jit_reset(reset_rng)\n",
        "  for i in range(env_cfg.episode_length // 2):\n",
        "    act_rng, rng = jax.random.split(rng)\n",
        "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "    actions.append(ctrl)\n",
        "    state = jit_step(state, ctrl)\n",
        "    rollout.append(state)\n",
        "    rewards.append(\n",
        "        {k[7:]: v for k, v in state.metrics.items() if k.startswith(\"reward/\")}\n",
        "    )\n",
        "    torso_height.append(state.data.qpos[2])\n",
        "    torques.append(state.data.actuator_force)\n",
        "    qvel = state.data.qvel[6:]\n",
        "    power.append(jp.sum(jp.abs(qvel * state.data.actuator_force)))\n",
        "    qfrc_constraint.append(jp.linalg.norm(state.data.qfrc_constraint[6:]))\n",
        "    qvels.append(jp.max(jp.abs(qvel)))\n",
        "    frc = state.data.actuator_force\n",
        "    qvel = state.data.qvel[6:]\n",
        "    power1.append(jp.sum(frc * qvel))\n",
        "    power2.append(jp.sum(jp.abs(frc * qvel)))\n",
        "\n",
        "\n",
        "render_every = 2\n",
        "fps = 1.0 / eval_env.dt / render_every\n",
        "traj = rollout[::render_every]\n",
        "\n",
        "scene_option = mujoco.MjvOption()\n",
        "scene_option.geomgroup[2] = True\n",
        "scene_option.geomgroup[3] = False\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = True\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTFORCE] = False\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = False\n",
        "\n",
        "frames = eval_env.render(\n",
        "    traj, camera=\"side\", scene_option=scene_option, height=480, width=640\n",
        ")\n",
        "media.show_video(frames, fps=fps, loop=False)\n",
        "\n",
        "power = jp.array(power1)\n",
        "print(f\"Max power: {jp.max(power)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5p0Z3PPSRik"
      },
      "source": [
        "Notice that the above policy looks jittery and unlikely to transfer on the robot. The max power output is also quite high.\n",
        "\n",
        "The sim-to-real deployment of the handstand policy was trained using a curriculum on the `energy_termination_threshold`, `energy` and `dof_acc`, which are config values that penalize high torques and high power output. Let's finetune the above policy with a decreased  `energy_termination_threshold`, as well as non-zero values for `energy` and `dof_acc` rewards to get a smoother policy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrjoVL-_WN-r"
      },
      "source": [
        "### Finetune the previous checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTxAySRSSu96"
      },
      "outputs": [],
      "source": [
        "env_cfg = registry.get_default_config(env_name)\n",
        "env_cfg.energy_termination_threshold = 400  # lower energy termination threshold\n",
        "env_cfg.reward_config.energy = -0.003  # non-zero negative `energy` reward\n",
        "env_cfg.reward_config.dof_acc = -2.5e-7  # non-zero negative `dof_acc` reward\n",
        "\n",
        "FINETUNE_PATH = epath.Path(ckpt_path)\n",
        "latest_ckpts = list(FINETUNE_PATH.glob(\"*\"))\n",
        "latest_ckpts = [ckpt for ckpt in latest_ckpts if ckpt.is_dir()]\n",
        "latest_ckpts.sort(key=lambda x: int(x.name))\n",
        "latest_ckpt = latest_ckpts[-1]\n",
        "restore_checkpoint_path = latest_ckpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M5IqOR6z4bV"
      },
      "outputs": [],
      "source": [
        "x_data, y_data, y_dataerr = [], [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "make_inference_fn, params, metrics = train_fn(\n",
        "    environment=registry.load(env_name, config=env_cfg),\n",
        "    eval_env=registry.load(env_name, config=env_cfg),\n",
        "    wrap_env_fn=wrapper.wrap_for_brax_training,\n",
        "    restore_checkpoint_path=restore_checkpoint_path,  # restore from the checkpoint!\n",
        "    seed=1,\n",
        ")\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "print(f\"time to train: {times[-1] - times[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tzG8eY2lz4dk"
      },
      "outputs": [],
      "source": [
        "#@title Rollout and Render Finetune Policy\n",
        "inference_fn = make_inference_fn(params, deterministic=True)\n",
        "jit_inference_fn = jax.jit(inference_fn)\n",
        "\n",
        "eval_env = registry.load(env_name, config=env_cfg)\n",
        "jit_reset = jax.jit(eval_env.reset)\n",
        "jit_step = jax.jit(eval_env.step)\n",
        "\n",
        "rng = jax.random.PRNGKey(12345)\n",
        "rollout = []\n",
        "rewards = []\n",
        "torso_height = []\n",
        "actions = []\n",
        "torques = []\n",
        "power = []\n",
        "qfrc_constraint = []\n",
        "qvels = []\n",
        "power1 = []\n",
        "power2 = []\n",
        "for _ in range(10):\n",
        "  rng, reset_rng = jax.random.split(rng)\n",
        "  state = jit_reset(reset_rng)\n",
        "  for i in range(env_cfg.episode_length // 2):\n",
        "    act_rng, rng = jax.random.split(rng)\n",
        "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "    actions.append(ctrl)\n",
        "    state = jit_step(state, ctrl)\n",
        "    rollout.append(state)\n",
        "    rewards.append(\n",
        "        {k[7:]: v for k, v in state.metrics.items() if k.startswith(\"reward/\")}\n",
        "    )\n",
        "    torso_height.append(state.data.qpos[2])\n",
        "    torques.append(state.data.actuator_force)\n",
        "    qvel = state.data.qvel[6:]\n",
        "    power.append(jp.sum(jp.abs(qvel * state.data.actuator_force)))\n",
        "    qfrc_constraint.append(jp.linalg.norm(state.data.qfrc_constraint[6:]))\n",
        "    qvels.append(jp.max(jp.abs(qvel)))\n",
        "    frc = state.data.actuator_force\n",
        "    qvel = state.data.qvel[6:]\n",
        "    power1.append(jp.sum(frc * qvel))\n",
        "    power2.append(jp.sum(jp.abs(frc * qvel)))\n",
        "\n",
        "\n",
        "render_every = 2\n",
        "fps = 1.0 / eval_env.dt / render_every\n",
        "traj = rollout[::render_every]\n",
        "\n",
        "scene_option = mujoco.MjvOption()\n",
        "scene_option.geomgroup[2] = True\n",
        "scene_option.geomgroup[3] = False\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = True\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTFORCE] = False\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = False\n",
        "\n",
        "frames = eval_env.render(\n",
        "    traj, camera=\"side\", scene_option=scene_option, height=480, width=640\n",
        ")\n",
        "media.show_video(frames, fps=fps, loop=False)\n",
        "\n",
        "power = jp.array(power1)\n",
        "print(f\"Max power: {jp.max(power)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCyibqGMiAca"
      },
      "source": [
        "The final policy should exhibit smoother behavior and have less power output! Feel free to finetune the policy some more using different reward terms to get the best behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26o77FfWXvVp"
      },
      "source": [
        "# Bipedal\n",
        "\n",
        "MuJoCo Playground also comes with a host of bipedal environments, such as the Berkely Humanoid and the Unitree G1/H1. Let's demonstrate a joystick policy on the Berkeley Humanoid. The initial policy takes 17 minutes to train on an RTX 4090."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESNd18FUanPt"
      },
      "outputs": [],
      "source": [
        "env_name = 'BerkeleyHumanoidJoystickFlatTerrain'\n",
        "env = registry.load(env_name)\n",
        "env_cfg = registry.get_default_config(env_name)\n",
        "ppo_params = locomotion_params.brax_ppo_config(env_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nibLoRu8anPt"
      },
      "outputs": [],
      "source": [
        "x_data, y_data, y_dataerr = [], [], []\n",
        "times = [datetime.now()]\n",
        "\n",
        "randomizer = registry.get_domain_randomizer(env_name)\n",
        "ppo_training_params = dict(ppo_params)\n",
        "network_factory = ppo_networks.make_ppo_networks\n",
        "if \"network_factory\" in ppo_params:\n",
        "  del ppo_training_params[\"network_factory\"]\n",
        "  network_factory = functools.partial(\n",
        "      ppo_networks.make_ppo_networks,\n",
        "      **ppo_params.network_factory\n",
        "  )\n",
        "\n",
        "train_fn = functools.partial(\n",
        "    ppo.train, **dict(ppo_training_params),\n",
        "    network_factory=network_factory,\n",
        "    randomization_fn=randomizer,\n",
        "    progress_fn=progress\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16dqomv0anPt"
      },
      "outputs": [],
      "source": [
        "make_inference_fn, params, metrics = train_fn(\n",
        "    environment=env,\n",
        "    eval_env=registry.load(env_name, config=env_cfg),\n",
        "    wrap_env_fn=wrapper.wrap_for_brax_training,\n",
        ")\n",
        "print(f\"time to jit: {times[1] - times[0]}\")\n",
        "print(f\"time to train: {times[-1] - times[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sBHDF-JFanPt"
      },
      "outputs": [],
      "source": [
        "#@title Rollout and Render\n",
        "from mujoco_playground._src.gait import draw_joystick_command\n",
        "\n",
        "env = registry.load(env_name)\n",
        "eval_env = registry.load(env_name)\n",
        "jit_reset = jax.jit(eval_env.reset)\n",
        "jit_step = jax.jit(eval_env.step)\n",
        "jit_inference_fn = jax.jit(make_inference_fn(params, deterministic=True))\n",
        "\n",
        "rng = jax.random.PRNGKey(1)\n",
        "\n",
        "rollout = []\n",
        "modify_scene_fns = []\n",
        "\n",
        "x_vel = 1.0  #@param {type: \"number\"}\n",
        "y_vel = 0.0  #@param {type: \"number\"}\n",
        "yaw_vel = 0.0  #@param {type: \"number\"}\n",
        "command = jp.array([x_vel, y_vel, yaw_vel])\n",
        "\n",
        "phase_dt = 2 * jp.pi * eval_env.dt * 1.5\n",
        "phase = jp.array([0, jp.pi])\n",
        "\n",
        "for j in range(1):\n",
        "  print(f\"episode {j}\")\n",
        "  state = jit_reset(rng)\n",
        "  state.info[\"phase_dt\"] = phase_dt\n",
        "  state.info[\"phase\"] = phase\n",
        "  for i in range(env_cfg.episode_length):\n",
        "    act_rng, rng = jax.random.split(rng)\n",
        "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
        "    state = jit_step(state, ctrl)\n",
        "    if state.done:\n",
        "      break\n",
        "    state.info[\"command\"] = command\n",
        "    rollout.append(state)\n",
        "\n",
        "    xyz = np.array(state.data.xpos[eval_env.mj_model.body(\"torso\").id])\n",
        "    xyz += np.array([0, 0.0, 0])\n",
        "    x_axis = state.data.xmat[eval_env._torso_body_id, 0]\n",
        "    yaw = -np.arctan2(x_axis[1], x_axis[0])\n",
        "    modify_scene_fns.append(\n",
        "        functools.partial(\n",
        "            draw_joystick_command,\n",
        "            cmd=state.info[\"command\"],\n",
        "            xyz=xyz,\n",
        "            theta=yaw,\n",
        "            scl=np.linalg.norm(state.info[\"command\"]),\n",
        "        )\n",
        "    )\n",
        "\n",
        "render_every = 1\n",
        "fps = 1.0 / eval_env.dt / render_every\n",
        "print(f\"fps: {fps}\")\n",
        "traj = rollout[::render_every]\n",
        "mod_fns = modify_scene_fns[::render_every]\n",
        "\n",
        "scene_option = mujoco.MjvOption()\n",
        "scene_option.geomgroup[2] = True\n",
        "scene_option.geomgroup[3] = False\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_CONTACTPOINT] = True\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_TRANSPARENT] = False\n",
        "scene_option.flags[mujoco.mjtVisFlag.mjVIS_PERTFORCE] = False\n",
        "\n",
        "frames = eval_env.render(\n",
        "    traj,\n",
        "    camera=\"track\",\n",
        "    scene_option=scene_option,\n",
        "    width=640*2,\n",
        "    height=480,\n",
        "    modify_scene_fns=mod_fns,\n",
        ")\n",
        "media.show_video(frames, fps=fps, loop=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBtrAqns35sI"
      },
      "source": [
        "🙌 Hasta la vista!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "mjx_playground_madrona",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
